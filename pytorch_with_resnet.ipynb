{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset length: 60000\n",
      "test dataset length: 10000\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "print('train dataset length: {}'.format(len(train_dataset)))\n",
    "print('test dataset length: {}'.format(len(test_dataset)))\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv_1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn_1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv_2 = conv3x3(planes, planes)\n",
    "        self.bn_2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv_1(x)\n",
    "        out = self.bn_1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv_2(out)\n",
    "        out = self.bn_2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        block = BasicBlock\n",
    "        n = 2\n",
    "        self.inplanes = 16\n",
    "        self.conv_1 = nn.Conv2d(1, 16, kernel_size=3, padding=1,\n",
    "                                bias=False)\n",
    "        self.bn_1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.stage_1 = self._make_layer(block, 16, n)\n",
    "        self.stage_2 = self._make_layer(block, 32, n, stride=2)\n",
    "        self.stage_3 = self._make_layer(block, 64, n, stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # nn.init.xavier_normal(m.weight.data)\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = self.relu(x)     # 32x32\n",
    "\n",
    "        x = self.stage_1(x)  # 32x32\n",
    "        x = self.stage_2(x)  # 16x16\n",
    "        x = self.stage_3(x)  # 8x8\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv_1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (stage_1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv_1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (stage_2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (stage_3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Note: the resnet is not the same as the normal resnet18, resnet50 and so on.\n",
    "model = ResNet(num_classes=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # TODO:forward + backward + optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffers\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    test_total = 0\n",
    "    test_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "    train_acc = train_correct / train_total\n",
    "    test_acc = test_correct / test_total\n",
    "    print('[epoch]: {} | [train_acc]: {} | [test_acc]: {}'.format(epoch, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I trained the net not in the notebook, so just give the train and test result."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "100%|██████████| 3750/3750 [01:36<00:00, 38.94it/s]\n",
    "100%|██████████| 625/625 [00:06<00:00, 96.42it/s]\n",
    "[epoch]: 0 | [train_acc]: 0.7971833333333334 | [test_acc]: 0.9639\n",
    "100%|██████████| 3750/3750 [01:30<00:00, 41.21it/s]\n",
    " 98%|█████████▊| 615/625 [00:06<00:00, 96.27it/s]\n",
    " [epoch]: 1 | [train_acc]: 0.9680666666666666 | [test_acc]: 0.9787\n",
    "100%|██████████| 625/625 [00:06<00:00, 97.16it/s]\n",
    "100%|██████████| 3750/3750 [01:39<00:00, 27.56it/s]\n",
    "100%|█████████▉| 624/625 [00:07<00:00, 85.16it/s]\n",
    "[epoch]: 2 | [train_acc]: 0.9792166666666666 | [test_acc]: 0.9842\n",
    "100%|██████████| 625/625 [00:07<00:00, 81.90it/s]\n",
    "100%|██████████| 3750/3750 [01:39<00:00, 37.70it/s]\n",
    "100%|██████████| 625/625 [00:06<00:00, 99.11it/s] \n",
    "  0%|          | 0/3750 [00:00<?, ?it/s]\n",
    "  [epoch]: 3 | [train_acc]: 0.9836 | [test_acc]: 0.9859\n",
    "100%|██████████| 3750/3750 [01:29<00:00, 42.87it/s]\n",
    " 99%|█████████▉| 618/625 [00:06<00:00, 101.34it/s]\n",
    " [epoch]: 4 | [train_acc]: 0.9861833333333333 | [test_acc]: 0.9889\n",
    "100%|██████████| 625/625 [00:06<00:00, 95.28it/s] \n",
    "100%|██████████| 3750/3750 [01:29<00:00, 42.82it/s]\n",
    "100%|██████████| 625/625 [00:06<00:00, 100.33it/s]\n",
    "  0%|          | 0/3750 [00:00<?, ?it/s]\n",
    "  [epoch]: 5 | [train_acc]: 0.9891833333333333 | [test_acc]: 0.9887\n",
    "100%|██████████| 3750/3750 [01:31<00:00, 41.96it/s]\n",
    " 99%|█████████▊| 616/625 [00:06<00:00, 99.77it/s]\n",
    " [epoch]: 6 | [train_acc]: 0.9903 | [test_acc]: 0.9901\n",
    "100%|██████████| 625/625 [00:06<00:00, 97.60it/s]\n",
    "100%|██████████| 3750/3750 [01:36<00:00, 38.90it/s]\n",
    " 99%|█████████▉| 619/625 [00:07<00:00, 84.42it/s]\n",
    " [epoch]: 7 | [train_acc]: 0.9916333333333334 | [test_acc]: 0.9903\n",
    "100%|██████████| 625/625 [00:07<00:00, 88.04it/s]\n",
    "100%|██████████| 3750/3750 [01:42<00:00, 36.67it/s]\n",
    " 99%|█████████▊| 617/625 [00:06<00:00, 86.66it/s]\n",
    " [epoch]: 8 | [train_acc]: 0.99235 | [test_acc]: 0.99\n",
    "100%|██████████| 625/625 [00:06<00:00, 89.92it/s]\n",
    "100%|██████████| 3750/3750 [01:34<00:00, 39.54it/s]\n",
    "100%|██████████| 625/625 [00:06<00:00, 91.59it/s]\n",
    "[epoch]: 9 | [train_acc]: 0.9934333333333333 | [test_acc]: 0.9906"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final train accuracy is 99.34% and the test accuracy is 99.06%.\n",
    "#### Note: I didn't delicatedly adjust the parameters, the result maybe become better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
